{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "\n",
    "from mypkg.whitebox_infra.attribution import AttributionData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adjust_tensor_values(input_tensor: torch.Tensor, fallback_value: float = 100.0) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Adjusts tensor values according to the following rules:\n",
    "    - If x >= 1, keep x.\n",
    "    - If 0 < x < 1, replace x with 1/x.\n",
    "    - If x <= 0, replace x with fallback_value.\n",
    "    \"\"\"\n",
    "    # Calculate reciprocal, handle potential division by zero/negative results temporarily\n",
    "    reciprocal = torch.reciprocal(input_tensor)\n",
    "\n",
    "    # Apply conditions using torch.where\n",
    "    # Condition 1: x >= 1 -> keep original value\n",
    "    # Condition 2: 0 < x < 1 -> use reciprocal\n",
    "    # Condition 3: x <= 0 -> use fallback_value\n",
    "\n",
    "    # First, distinguish between >= 1 and < 1\n",
    "    adjusted = torch.where(input_tensor >= 1, input_tensor, reciprocal)\n",
    "\n",
    "    # Then, handle the case where input_tensor <= 0, replacing potentially inf/negative reciprocals\n",
    "    final_adjusted = torch.where(input_tensor <= 0, torch.tensor(fallback_value, dtype=input_tensor.dtype), adjusted)\n",
    "\n",
    "    return final_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_score_path = \"data/cached_responses/0410_data_v2/score_output_0410/google_gemma-2-2b-it\"\n",
    "attrib_path = \"attribution_results/google_gemma-2-2b-it\"\n",
    "\n",
    "BIAS_DIRECTION_PAIRS = {\n",
    "    \"gender\": (\"Male\", \"Female\"),\n",
    "    \"race\": (\"White\", \"African_American\"),\n",
    "    \"politics\": (\"Republican\", \"Democrat\")\n",
    "}\n",
    "\n",
    "bias_key_map = {\n",
    "    \"gender\": \"gender_rates\",\n",
    "    \"race\": \"race_rates\",\n",
    "    \"politics\": \"politics_rates\",  # For Democrat/Republican/None\n",
    "}\n",
    "\n",
    "def get_bias_scores(bias_type: str, bias_score_path: str) -> dict[str, dict[str, float]]:\n",
    "\n",
    "    bias_score_files = sorted([f for f in os.listdir(bias_score_path) if f.endswith(\".json\")])\n",
    "\n",
    "    long_key_suffix = \"_meta_job_description.txt\"\n",
    "    short_key_suffix = \"_short_meta_job_description.txt\"\n",
    "\n",
    "    grouped_data = {}  # version -> {short/long -> {cat -> score}}\n",
    "\n",
    "    for fname in bias_score_files:\n",
    "        fpath = os.path.join(bias_score_path, fname)\n",
    "        with open(fpath) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        version_num = fname.split(\"_v\")[-1].split(\".json\")[0].lstrip(\"v\")\n",
    "\n",
    "        if int(version_num) >= 17:\n",
    "            continue\n",
    "\n",
    "        grouped_data[version_num] = {\"short\": {}, \"long\": {}}\n",
    "\n",
    "        for key, val in data.items():\n",
    "            rates = val[\"bias_scores\"].get(bias_key_map[bias_type], {})\n",
    "            if short_key_suffix in key:\n",
    "                grouped_data[version_num][\"short\"] = rates\n",
    "            elif long_key_suffix in key:\n",
    "                grouped_data[version_num][\"long\"] = rates\n",
    "\n",
    "    versions = sorted(grouped_data.keys(), key=int)\n",
    "    categories = sorted({cat for v in versions for src in [\"short\", \"long\"] for cat in grouped_data[v][src].keys()})\n",
    "\n",
    "    g1, g2 = BIAS_DIRECTION_PAIRS[bias_type]\n",
    "    bias = {}\n",
    "\n",
    "    for v in versions:\n",
    "        bias[v] = {}\n",
    "        short = grouped_data[v][\"short\"]\n",
    "        long = grouped_data[v][\"long\"]\n",
    "        bias[v][\"short\"] = short[g1] - short[g2]\n",
    "        bias[v][\"long\"] = long[g1] - long[g2]\n",
    "\n",
    "    return bias\n",
    "\n",
    "bias_type = \"race\"\n",
    "# bias_type = \"gender\"\n",
    "# bias_type = \"politics\"\n",
    "bias_scores = get_bias_scores(bias_type, bias_score_path)\n",
    "print(bias_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attrib_ratios(bias_type: str, attrib_path: str) -> dict[str, dict[str, float]]:\n",
    "    attrib_files = sorted([f for f in os.listdir(attrib_path) if \"layer_25\" in f])\n",
    "\n",
    "    grouped_data = {}\n",
    "\n",
    "    for file in attrib_files:\n",
    "        version_num = file.split(\"_trainer\")[0].split(\"v\")[1]\n",
    "\n",
    "        filename = os.path.join(attrib_path, file)\n",
    "        data = torch.load(filename)\n",
    "\n",
    "        # Hack to make the key names match\n",
    "        if bias_type == \"politics\":\n",
    "            bias_type = \"political_orientation\"\n",
    "\n",
    "        attribution_data = AttributionData.from_dict(data[bias_type])\n",
    "\n",
    "        effects_F = attribution_data.pos_effects_F - attribution_data.neg_effects_F\n",
    "        \n",
    "        k = 20\n",
    "\n",
    "        top_k_ids = effects_F.abs().topk(k).indices\n",
    "        top_k_vals = effects_F[top_k_ids]\n",
    "\n",
    "        act_ratios_F = attribution_data.pos_sae_acts_F / attribution_data.neg_sae_acts_F\n",
    "\n",
    "        top_k_act_ratios = act_ratios_F[top_k_ids]\n",
    "\n",
    "        adjusted_act_ratios = adjust_tensor_values(top_k_act_ratios)\n",
    "\n",
    "        grouped_data[version_num] = {\n",
    "            # \"effects_F\": effects_F,\n",
    "            # \"act_ratios_F\": act_ratios_F,\n",
    "            \"adjusted_act_ratios\": adjusted_act_ratios\n",
    "        }\n",
    "\n",
    "    return grouped_data\n",
    "        \n",
    "attrib_ratios = get_attrib_ratios(bias_type, attrib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attrib_ratios.keys())\n",
    "print(bias_scores.keys())\n",
    "print(bias_scores[\"1\"][\"long\"])\n",
    "\n",
    "print(attrib_ratios[\"1\"][\"adjusted_act_ratios\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pandas as pd, numpy as np\n",
    "\n",
    "# ---- 1. pull out the 20-element vectors ----\n",
    "attrib_values = {\n",
    "    int(k): (v[\"adjusted_act_ratios\"].tolist()               # tensor  ➜ python list\n",
    "             if hasattr(v[\"adjusted_act_ratios\"], \"tolist\")\n",
    "             else v[\"adjusted_act_ratios\"])\n",
    "    for k, v in attrib_ratios.items()\n",
    "    if \"adjusted_act_ratios\" in v                            # sanity-check\n",
    "}\n",
    "\n",
    "# ---- 2. pull out the bias scalars ----\n",
    "bias_values = {\n",
    "    int(k): v[\"long\"]\n",
    "    for k, v in bias_scores.items()\n",
    "    if \"long\" in v\n",
    "}\n",
    "\n",
    "# ---- 3. build the tidy DataFrame (intersection of keys) ----\n",
    "common = sorted(set(attrib_values) & set(bias_values))       # keep only keys present in both\n",
    "\n",
    "attrib_df = pd.DataFrame(\n",
    "    [attrib_values[k] for k in common],\n",
    "    index=common,\n",
    "    columns=[f\"r{i}\" for i in range(20)],\n",
    ")\n",
    "\n",
    "bias_s = pd.Series({k: bias_values[k] for k in common}, name=\"bias\")\n",
    "\n",
    "df = attrib_df.join(bias_s)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Summary-stat notebook cell -------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 0. sanity-check -----------------------------------------------------\n",
    "if \"df\" not in globals():\n",
    "    raise NameError(\"⚠️  You need to run the cell that builds `df` first!\")\n",
    "\n",
    "# 1. helper functions -------------------------------------------------\n",
    "def sum_excess(arr):\n",
    "    \"\"\"Unweighted positive mass above 1.\"\"\"\n",
    "    return np.maximum(arr - 1, 0).sum()\n",
    "\n",
    "def sum_excess_signed(arr):\n",
    "    \"\"\"Signed sum of deviations from 1.\"\"\"\n",
    "    return (arr - 1).sum()\n",
    "\n",
    "def decay_sum_excess(arr, decay=0.9):\n",
    "    \"\"\"Geometrically-decayed positive excess.\"\"\"\n",
    "    weights = decay ** np.arange(len(arr))\n",
    "    return np.maximum(arr - 1, 0).dot(weights)\n",
    "\n",
    "summary_funcs = {\n",
    "    \"sum_excess\"        : sum_excess,\n",
    "    \"sum_excess_signed\" : sum_excess_signed,\n",
    "    \"decay_excess_0.9\"  : lambda r: decay_sum_excess(r, 0.9),\n",
    "    \"decay_excess_0.8\"  : lambda r: decay_sum_excess(r, 0.8),\n",
    "}\n",
    "\n",
    "# 2. compute / append new columns ------------------------------------\n",
    "ratios_mat = df[[f\"r{i}\" for i in range(20)]].values\n",
    "for name, fn in summary_funcs.items():\n",
    "    df[name] = np.apply_along_axis(fn, 1, ratios_mat)\n",
    "\n",
    "summary_cols = list(summary_funcs.keys())\n",
    "\n",
    "# 3. scatter plots ----------------------------------------------------\n",
    "for col in summary_cols:\n",
    "    plt.figure()\n",
    "    plt.scatter(df[col], df[\"bias\"])\n",
    "    plt.xlabel(col);  plt.ylabel(\"bias\")\n",
    "    plt.title(f\"{col}  vs  bias\")\n",
    "    plt.show()\n",
    "\n",
    "# 4. correlation bar chart -------------------------------------------\n",
    "corr = df[summary_cols + [\"bias\"]].corr(numeric_only=True)[\"bias\"].drop(\"bias\")\n",
    "plt.figure()\n",
    "corr.sort_values().plot(kind=\"barh\")\n",
    "plt.xlabel(\"Pearson r\"); plt.title(\"Correlation of summary stats with bias\")\n",
    "plt.show()\n",
    "# --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrib_files = sorted([f for f in os.listdir(attrib_path) if \"layer_25\" in f])\n",
    "\n",
    "# first_file = attrib_files[0]\n",
    "\n",
    "# filename = os.path.join(attrib_path, first_file)\n",
    "\n",
    "# data = torch.load(filename)\n",
    "\n",
    "# torch.set_printoptions(precision=5, sci_mode=False)\n",
    "\n",
    "# # print(data)\n",
    "# attribution_data = AttributionData.from_dict(data[\"race\"])\n",
    "\n",
    "# effects_F = attribution_data.pos_effects_F - attribution_data.neg_effects_F\n",
    "\n",
    "# k = 20\n",
    "\n",
    "# top_k_ids = effects_F.abs().topk(k).indices\n",
    "# top_k_vals = effects_F[top_k_ids]\n",
    "\n",
    "# print(top_k_ids)\n",
    "# print(top_k_vals)\n",
    "\n",
    "# effect_ratios = attribution_data.pos_effects_F / attribution_data.neg_effects_F\n",
    "\n",
    "# print(attribution_data.pos_effects_F[top_k_ids])\n",
    "# print(attribution_data.neg_effects_F[top_k_ids])\n",
    "# print(effect_ratios[top_k_ids])\n",
    "\n",
    "# act_diff_F = attribution_data.pos_sae_acts_F - attribution_data.neg_sae_acts_F\n",
    "\n",
    "# print(act_diff_F[top_k_ids])\n",
    "\n",
    "# acts_ratio_F = attribution_data.pos_sae_acts_F / attribution_data.neg_sae_acts_F\n",
    "\n",
    "# print(acts_ratio_F[top_k_ids])\n",
    "\n",
    "# adjusted_acts_ratio_F = adjust_tensor_values(acts_ratio_F[top_k_ids])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(adjust_tensor_values(acts_ratio_F[top_k_ids]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
