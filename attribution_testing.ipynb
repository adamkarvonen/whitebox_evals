{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from typing import Callable, Optional\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import mypkg.whitebox_infra.attribution as attribution\n",
    "import mypkg.whitebox_infra.dictionaries.batch_topk_sae as batch_topk_sae\n",
    "import mypkg.whitebox_infra.data_utils as data_utils\n",
    "import mypkg.whitebox_infra.model_utils as model_utils\n",
    "import mypkg.whitebox_infra.interp_utils as interp_utils\n",
    "import mypkg.pipeline.setup.dataset as dataset_setup\n",
    "import mypkg.pipeline.infra.hiring_bias_prompts as hiring_bias_prompts\n",
    "from mypkg.eval_config import EvalConfig\n",
    "import mypkg.pipeline.infra.model_inference as model_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"mistralai/Ministral-8B-Instruct-2410\"\n",
    "model_name = \"mistralai/Mistral-Small-24B-Instruct-2501\"\n",
    "# model_name = \"google/gemma-2-9b-it\"\n",
    "# model_name = \"google/gemma-2-27b-it\"\n",
    "\n",
    "bias_type = \"gender\"\n",
    "bias_type = \"race\"\n",
    "# bias_type = \"political_orientation\"\n",
    "\n",
    "anti_bias_statement_file = \"v1.txt\"\n",
    "anti_bias_statement_file = \"v3.txt\"\n",
    "# anti_bias_statement_file = \"v17.txt\"\n",
    "\n",
    "args = hiring_bias_prompts.HiringBiasArgs(\n",
    "    political_orientation=bias_type == \"political_orientation\",\n",
    "    employment_gap=bias_type == \"employment_gap\",\n",
    "    pregnancy=bias_type == \"pregnancy\",\n",
    "    race=bias_type == \"race\",\n",
    "    gender=bias_type == \"gender\",\n",
    ")\n",
    "\n",
    "\n",
    "dtype = torch.bfloat16\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, torch_dtype=dtype, device_map=device\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "gradient_checkpointing = False\n",
    "\n",
    "if model_name == \"google/gemma-2-27b-it\":\n",
    "    gradient_checkpointing = True\n",
    "    batch_size = 1\n",
    "elif model_name == \"mistralai/Mistral-Small-24B-Instruct-2501\":\n",
    "    batch_size = 1\n",
    "else:\n",
    "    batch_size = 3\n",
    "\n",
    "if gradient_checkpointing:\n",
    "    model.config.use_cache = False\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "\n",
    "chosen_layer_percentage = [25]\n",
    "# chosen_layer_percentage = [50]\n",
    "\n",
    "system_prompt = \"yes_no.txt\"\n",
    "\n",
    "chosen_layers = []\n",
    "for layer_percent in chosen_layer_percentage:\n",
    "    chosen_layers.append(model_utils.MODEL_CONFIGS[model_name][\"layer_mappings\"][layer_percent][\"layer\"])\n",
    "\n",
    "eval_config = EvalConfig(\n",
    "        model_name=model_name,\n",
    "        political_orientation=True,\n",
    "        pregnancy=False,\n",
    "        employment_gap=False,\n",
    "        anthropic_dataset=False,\n",
    "        downsample=50,\n",
    "        # downsample=10,\n",
    "        gpu_inference=True,\n",
    "        anti_bias_statement_file=anti_bias_statement_file,\n",
    "        job_description_file=\"short_meta_job_description.txt\",\n",
    "        system_prompt_filename=system_prompt,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sae_repo = \"adamkarvonen/ministral_saes\"\n",
    "# sae_path = f\"mistralai_Ministral-8B-Instruct-2410_batch_top_k/resid_post_layer_{chosen_layers[0]}/trainer_1/ae.pt\"\n",
    "\n",
    "# sae = batch_topk_sae.load_dictionary_learning_batch_topk_sae(\n",
    "#     repo_id=sae_repo,\n",
    "#     filename=sae_path,\n",
    "#     model_name=model_name,\n",
    "#     device=device,\n",
    "#     dtype=dtype,\n",
    "#     layer=chosen_layers[0],\n",
    "#     local_dir=\"downloaded_saes\",\n",
    "# )\n",
    "trainer_id = 2\n",
    "\n",
    "if \"gemma\" in model_name:\n",
    "    trainer_id = 0\n",
    "    \n",
    "sae = model_utils.load_model_sae(model_name, device, dtype, chosen_layer_percentage[0], trainer_id=trainer_id)\n",
    "\n",
    "submodules = [model_utils.get_submodule(model, chosen_layers[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_setup.load_raw_dataset()\n",
    "\n",
    "industry = \"INFORMATION-TECHNOLOGY\"\n",
    "downsample = eval_config.downsample\n",
    "random_seed = eval_config.random_seed\n",
    "\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "df = dataset_setup.filter_by_industry(df, industry)\n",
    "\n",
    "df = dataset_setup.balanced_downsample(df, downsample, random_seed)\n",
    "\n",
    "\n",
    "\n",
    "prompts = hiring_bias_prompts.create_all_prompts_hiring_bias(df, args, eval_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels = hiring_bias_prompts.process_hiring_bias_resumes_prompts(prompts, args)\n",
    "\n",
    "train_texts = model_utils.add_chat_template(train_texts, model_name)\n",
    "\n",
    "dataloader = data_utils.create_simple_dataloader(\n",
    "    train_texts, train_labels, model_name, device, batch_size=batch_size, max_length=2500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_answers = model_inference.run_single_forward_pass_transformers(\n",
    "#     prompts, model_name, batch_size=batch_size * 6, model=model\n",
    "# )\n",
    "\n",
    "# bias_scores = hiring_bias_prompts.evaluate_bias(\n",
    "#     model_answers,\n",
    "#     system_prompt\n",
    "# )\n",
    "# print(bias_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_acts_F = attribution.get_activations(model, sae, dataloader, submodules, chosen_layers, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_top_k_ids = diff_acts_F.abs().topk(20).indices\n",
    "print(acts_top_k_ids)\n",
    "\n",
    "acts_top_k_vals = diff_acts_F[acts_top_k_ids]\n",
    "print(acts_top_k_vals)\n",
    "\n",
    "output_filename = os.path.join(\n",
    "    \"diff_acts\",\n",
    "    f\"{eval_config.anti_bias_statement_file.replace('.txt', '')}_trainer_{trainer_id}_model_{model_name.replace('/', '_')}_layer_{chosen_layer_percentage[0]}_attrib_data.pt\",\n",
    ")\n",
    "print(output_filename)\n",
    "\n",
    "os.makedirs(\"diff_acts\", exist_ok=True)\n",
    "\n",
    "diff_acts = {\"diff_acts_F\": diff_acts_F}\n",
    "diff_acts[\"config\"] = {\n",
    "        \"model_name\": model_name,\n",
    "        \"layer\": chosen_layers[0],\n",
    "        \"bias_categories\": \"N\\A\",\n",
    "        \"anti_bias_statement_file\": eval_config.anti_bias_statement_file,\n",
    "        \"downsample\": eval_config.downsample,\n",
    "        \"random_seed\": eval_config.random_seed,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"chosen_layer_percentage\": chosen_layer_percentage,\n",
    "        \"trainer_id\": trainer_id,\n",
    "    }\n",
    "\n",
    "torch.save(diff_acts, output_filename)\n",
    "\n",
    "# tensor([23759, 42925, 33394, 45780, 10085, 23574, 30460, 61472,   521, 59020,\n",
    "#           775,  4261, 41205, 29588, 44488,   983, 55773, 44225, 42612, 30063],\n",
    "#        device='cuda:0')\n",
    "# tensor([-2.2821e-05, -1.8463e-05, -1.8400e-05,  1.6533e-05, -1.6091e-05,\n",
    "#          1.5563e-05,  1.5402e-05,  1.4945e-05, -1.4770e-05, -1.4396e-05,\n",
    "#         -1.4326e-05, -1.4277e-05, -1.3993e-05,  1.3824e-05, -1.3621e-05,\n",
    "#         -1.2731e-05,  1.2631e-05,  1.2598e-05, -1.2597e-05, -1.2533e-05],\n",
    "#        device='cuda:0')\n",
    "# diff_acts/v1_trainer_3_model_mistralai_Ministral-8B-Instruct-2410_layer_50_attrib_data.pt\n",
    "\n",
    "# tensor([24895, 37973, 29596, 35104, 19677, 64690, 23575, 14460, 54626, 60262,\n",
    "#         36264, 10894,  2577,  6381, 25218, 17486, 50206,  1279,  9861, 26352],\n",
    "#        device='cuda:0')\n",
    "# tensor([-0.0399, -0.0257,  0.0186, -0.0184,  0.0138,  0.0096,  0.0089, -0.0089,\n",
    "#         -0.0082, -0.0079, -0.0077,  0.0074,  0.0067, -0.0066, -0.0062, -0.0060,\n",
    "#          0.0056,  0.0050,  0.0046,  0.0046], device='cuda:0')\n",
    "# diff_acts/v17_trainer_2_model_mistralai_Mistral-Small-24B-Instruct-2501_layer_50_attrib_data.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the custom loss function\n",
    "yes_vs_no_loss_fn = attribution.make_yes_no_loss_fn(\n",
    "    tokenizer,\n",
    "    yes_candidates=[\"yes\", \" yes\", \"Yes\", \" Yes\", \"YES\", \" YES\"],\n",
    "    no_candidates=[\"no\", \" no\", \"No\", \" No\", \"NO\", \" NO\"],\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "effects_F, error_effect, predicted_tokens = attribution.get_effects(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    sae,\n",
    "    dataloader,\n",
    "    yes_vs_no_loss_fn,\n",
    "    submodules,\n",
    "    chosen_layers,\n",
    "    device,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Print peak memory usage\n",
    "if torch.cuda.is_available():\n",
    "    peak_memory = torch.cuda.max_memory_allocated() / 1024**2  # Convert to MB\n",
    "    print(f\"Peak CUDA memory usage: {peak_memory:.2f} MB\")\n",
    "\n",
    "# Peak CUDA memory usage: 33432.72 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_ids = effects_F.abs().topk(20).indices\n",
    "print(top_k_ids)\n",
    "\n",
    "top_k_vals = effects_F[top_k_ids]\n",
    "print(top_k_vals)\n",
    "\n",
    "print(error_effect)\n",
    "\n",
    "# tensor([ 4393, 15242,  9049,  3959, 11802, 14960,   428,  9920,  2715,  3509,\n",
    "#          9444, 12979,  9319,  8910, 12243,  7781, 11637, 10283,  4204,  2557],\n",
    "#        device='cuda:0')\n",
    "# tensor([0.0074, 0.0058, 0.0033, 0.0016, 0.0016, 0.0013, 0.0011, 0.0009, 0.0008,\n",
    "#         0.0008, 0.0008, 0.0008, 0.0007, 0.0007, 0.0007, 0.0007, 0.0006, 0.0006,\n",
    "#         0.0006, 0.0005], device='cuda:0')\n",
    "\n",
    "# tensor([ 4393, 15242,  9049, 13855, 11802,  3959,  2039, 14960,  1683,  3509,\n",
    "#           428,  4794,  3645,  9920,  5911,  1160,  1656, 16078,  9319,   394],\n",
    "#        device='cuda:0')\n",
    "# tensor([ 0.0305,  0.0242,  0.0133, -0.0078,  0.0064,  0.0063, -0.0058,  0.0052,\n",
    "#         -0.0051,  0.0050,  0.0045, -0.0043, -0.0042,  0.0040, -0.0039, -0.0034,\n",
    "#         -0.0033, -0.0033,  0.0033, -0.0031], device='cuda:0')\n",
    "# tensor(-0.0181, device='cuda:0')\n",
    "\n",
    "# tensor([ 4393, 15242,  9049, 13855, 11802,  3645,  2039,  3959,  1683,  3509,\n",
    "#         14960,  9920,  4794,  1656,  5911, 16078,  9319,  1160,  5286,   394],\n",
    "#        device='cuda:0')\n",
    "# tensor([ 0.0276,  0.0227,  0.0114, -0.0077,  0.0062, -0.0058, -0.0056,  0.0055,\n",
    "#         -0.0049,  0.0047,  0.0046,  0.0038, -0.0036, -0.0035, -0.0034, -0.0034,\n",
    "#          0.0033, -0.0032, -0.0030, -0.0029], device='cuda:0')\n",
    "# tensor(-0.0127, device='cuda:0')\n",
    "\n",
    "# tensor([15658, 54626, 17662, 37447, 26352, 13920, 47911,   413,   204, 39717,\n",
    "#         52330, 24031, 62241, 53133, 14038,  4682, 13032, 61127, 46104,  9405],\n",
    "#        device='cuda:0')\n",
    "# tensor([ 0.3070,  0.1780,  0.1460,  0.1291,  0.1048, -0.0993, -0.0823,  0.0779,\n",
    "#          0.0748,  0.0666,  0.0586,  0.0581, -0.0442, -0.0442,  0.0392,  0.0377,\n",
    "#         -0.0370,  0.0332, -0.0313, -0.0293], device='cuda:0')\n",
    "# tensor(-0.0644, device='cuda:0')\n",
    "\n",
    "# tensor([33592,  3662, 47196, 52209,  9593, 18947, 64744, 50582, 45795,   574,\n",
    "#         57031, 61625, 33006, 53980, 46136,  4975, 12936, 32874,  6954, 38436],\n",
    "#        device='cuda:0')\n",
    "# tensor([ 0.1563, -0.1505, -0.1254,  0.1122,  0.1059,  0.1016, -0.0913, -0.0874,\n",
    "#         -0.0841, -0.0828, -0.0805,  0.0714,  0.0673,  0.0635, -0.0592, -0.0583,\n",
    "#          0.0563,  0.0545, -0.0545, -0.0544], device='cuda:0')\n",
    "# tensor(0.0565, device='cuda:0')\n",
    "\n",
    "# downsample 10\n",
    "# tensor([63073,  3662, 45795, 33006, 58683, 50582, 45304, 42524, 33592, 27866,\n",
    "#         21772, 12936, 25266, 57031, 15390, 60822, 64744, 44535, 60211,   169],\n",
    "#        device='cuda:0')\n",
    "# tensor([-0.5895, -0.2480, -0.2339,  0.2267,  0.2038, -0.1890, -0.1808,  0.1536,\n",
    "#          0.1423, -0.1383, -0.1340,  0.1250, -0.1238, -0.1221,  0.1199,  0.1138,\n",
    "#         -0.1091, -0.1051,  0.1040,  0.0992], device='cuda:0')\n",
    "# tensor(0.6601, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = set(acts_top_k_ids.cpu().tolist())\n",
    "set2 = set(top_k_ids.cpu().tolist())\n",
    "\n",
    "print(set1)\n",
    "print(set2)\n",
    "\n",
    "print(set1.intersection(set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sae.W_dec.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_dir = \"max_acts\"\n",
    "acts_filename = f\"acts_{model_name}_layer_{chosen_layers[0]}_trainer_{trainer_id}_layer_percent_{chosen_layer_percentage[0]}.pt\".replace(\"/\", \"_\")\n",
    "if not os.path.exists(acts_filename):\n",
    "    from huggingface_hub import hf_hub_download\n",
    "    path_to_config = hf_hub_download(\n",
    "        repo_id=\"adamkarvonen/sae_max_acts\",\n",
    "        filename=acts_filename,\n",
    "        force_download=False,\n",
    "        local_dir=acts_dir,\n",
    "        repo_type=\"dataset\",\n",
    "    )\n",
    "\n",
    "    acts_path = os.path.join(acts_dir, acts_filename)\n",
    "    acts_data = torch.load(acts_path)\n",
    "    \n",
    "    # max_tokens, max_acts = interp_utils.get_interp_prompts(\n",
    "    #     model,\n",
    "    #     submodules[0],\n",
    "    #     sae,\n",
    "    #     torch.tensor(list(range(sae.W_dec.shape[0]))),\n",
    "    #     context_length=128,\n",
    "    #     tokenizer=tokenizer,\n",
    "    #     batch_size=batch_size * 32,\n",
    "    #     num_tokens=30_000_000,\n",
    "    # )\n",
    "    # acts_data = {\n",
    "    #     \"max_tokens\": max_tokens,\n",
    "    #     \"max_acts\": max_acts,\n",
    "    # }\n",
    "    # torch.save(acts_data, acts_filename)\n",
    "else:\n",
    "    acts_path = os.path.join(acts_dir, acts_filename)\n",
    "    acts_data = torch.load(acts_path)\n",
    "max_tokens = acts_data[\"max_tokens\"].cpu()\n",
    "max_acts = acts_data[\"max_acts\"].cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuitsvis.activations import text_neuron_activations\n",
    "import gc\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "\n",
    "# def _list_decode(x):\n",
    "#     if len(x.shape) == 0:\n",
    "#         return tokenizer.decode(x, skip_special_tokens=False)\n",
    "#     else:\n",
    "#         return [_list_decode(y) for y in x]\n",
    "\n",
    "def _list_decode(x: torch.Tensor):\n",
    "    assert len(x.shape) == 1 or len(x.shape) == 2\n",
    "    # Convert to list of lists, even if x is 1D\n",
    "    if len(x.shape) == 1:\n",
    "        x = x.unsqueeze(0)  # Make it 2D for consistent handling\n",
    "\n",
    "    # Convert tensor to list of list of ints\n",
    "    token_ids = x.tolist()\n",
    "    \n",
    "    # Convert token ids to token strings\n",
    "    return [tokenizer.batch_decode(seq, skip_special_tokens=False) for seq in token_ids]\n",
    "\n",
    "\n",
    "def create_html_activations(\n",
    "    selected_tokens_FKL: list[str],\n",
    "    selected_activations_FKL: list[torch.Tensor],\n",
    "    num_display: int = 10,\n",
    "    k: int = 5,\n",
    "):\n",
    "\n",
    "    all_html_activations = []\n",
    "\n",
    "    for i in range(num_display):\n",
    "\n",
    "        selected_activations_KL11 = [\n",
    "            selected_activations_FKL[i, k, :, None, None] for k in range(k)\n",
    "        ]\n",
    "        selected_tokens_KL = selected_tokens_FKL[i]\n",
    "        selected_token_strs_KL = _list_decode(selected_tokens_KL)\n",
    "\n",
    "        # print(selected_token_strs_KL)\n",
    "\n",
    "        for k in range(len(selected_token_strs_KL)):\n",
    "            if (\n",
    "                \"<s>\" in selected_token_strs_KL[k][0]\n",
    "                or \"<bos>\" in selected_token_strs_KL[k][0]\n",
    "            ):\n",
    "                selected_token_strs_KL[k][0] = \"BOS>\"\n",
    "\n",
    "        # selected_token_strs_KL = tokenizer.batch_decode(selected_token_KL, skip_special_tokens=False)\n",
    "        # for k in range(len(selected_token_strs_KL)):\n",
    "        #     string = selected_token_strs_KL[k]\n",
    "        #     print(string[:10])\n",
    "        # print(\"\".join(string))\n",
    "\n",
    "        html_activations = text_neuron_activations(\n",
    "            selected_token_strs_KL, selected_activations_KL11\n",
    "        )\n",
    "\n",
    "        all_html_activations.append(html_activations)\n",
    "    \n",
    "    return all_html_activations\n",
    "\n",
    "clear_output(wait=True)\n",
    "gc.collect()\n",
    "html_activations = create_html_activations(max_tokens[top_k_ids.cpu()], max_acts[top_k_ids.cpu()], num_display=20)\n",
    "\n",
    "with open(\"autointerp_html_activations.pkl\", \"wb\") as f:\n",
    "    pickle.dump(html_activations, f)\n",
    "\n",
    "for i, html_activation in enumerate(html_activations):\n",
    "    feature_idx = top_k_ids[i]\n",
    "    feature_val = top_k_vals[i]\n",
    "    print(f\"Feature {i}, feature idx: {feature_idx}, value: {feature_val}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from copy import deepcopy\n",
    "\n",
    "# random.seed(random_seed)\n",
    "# torch.manual_seed(random_seed)\n",
    "\n",
    "# inspection_eval_config = deepcopy(eval_config)\n",
    "# inspection_eval_config.downsample = 3\n",
    "\n",
    "# inspect_df = dataset_setup.balanced_downsample(df, inspection_eval_config.downsample, random_seed)\n",
    "\n",
    "# inspect_prompts = hiring_bias_prompts.create_all_prompts_hiring_bias(inspect_df, args, inspection_eval_config)\n",
    "\n",
    "# inspect_texts, inspect_labels = hiring_bias_prompts.process_hiring_bias_resumes_prompts(inspect_prompts, args)\n",
    "\n",
    "# inspect_texts = model_utils.add_chat_template(inspect_texts, model_name)\n",
    "\n",
    "# inspect_tokens_FBL, inspect_activations_FBL = interp_utils.get_interp_prompts_user_inputs(\n",
    "#     model,\n",
    "#     submodules[0],\n",
    "#     sae,\n",
    "#     top_k_ids,\n",
    "#     inspect_texts,\n",
    "#     tokenizer=tokenizer,\n",
    "#     batch_size=batch_size * 6,\n",
    "#     k=len(inspect_texts),\n",
    "#     sort_by_activation=False,\n",
    "# )\n",
    "\n",
    "# print(inspect_tokens_FBL.shape)\n",
    "# print(inspect_activations_FBL.shape)\n",
    "# print(inspect_labels)\n",
    "\n",
    "# labels_tensor = torch.tensor(inspect_labels)\n",
    "\n",
    "# pos_mask_K = labels_tensor == 1\n",
    "# neg_mask_K = labels_tensor == 0\n",
    "\n",
    "# print(pos_mask_K)\n",
    "# print(neg_mask_K)\n",
    "\n",
    "# print(inspect_activations_FBL.shape)\n",
    "\n",
    "# pos_acts_FKL = inspect_activations_FBL[:, pos_mask_K, :]\n",
    "# neg_acts_FKL = inspect_activations_FBL[:, neg_mask_K, :]\n",
    "\n",
    "# mean_pos_acts_F = pos_acts_FKL.mean(dim=(1,2))\n",
    "# mean_neg_acts_F = neg_acts_FKL.mean(dim=(1,2))\n",
    "\n",
    "# torch.set_printoptions(precision=4, sci_mode=False)\n",
    "\n",
    "# print(mean_pos_acts_F)\n",
    "# print(mean_neg_acts_F)\n",
    "\n",
    "# ratios = mean_pos_acts_F / mean_neg_acts_F\n",
    "\n",
    "# print(ratios)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attrib_acts(\n",
    "    model: AutoModelForCausalLM,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    sae: batch_topk_sae.BatchTopKSAE,\n",
    "    top_k_ids: torch.Tensor,\n",
    "    batch_size: int,\n",
    "    device: torch.device,\n",
    "    chosen_layers: list[int],\n",
    "    submodules: list[torch.nn.Module],\n",
    "    yes_vs_no_loss_fn: Callable,\n",
    "    downsample: int\n",
    ") -> list[dict]:\n",
    "    random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "\n",
    "    inspection_eval_config = deepcopy(eval_config)\n",
    "    inspection_eval_config.downsample = downsample\n",
    "    inspection_eval_config.anti_bias_statement_file = anti_bias_statement_file\n",
    "    # inspection_eval_config.anti_bias_statement_file = \"v1.txt\"\n",
    "    # inspection_eval_config.anti_bias_statement_file = \"v17.txt\"\n",
    "    # inspection_eval_config.anti_bias_statement_file = \"v6.txt\"\n",
    "\n",
    "    inspect_df = dataset_setup.balanced_downsample(\n",
    "        df, inspection_eval_config.downsample, random_seed\n",
    "    )\n",
    "\n",
    "    inspect_prompts = hiring_bias_prompts.create_all_prompts_hiring_bias(\n",
    "        inspect_df, args, inspection_eval_config\n",
    "    )\n",
    "\n",
    "    inspect_texts, inspect_labels = (\n",
    "        hiring_bias_prompts.process_hiring_bias_resumes_prompts(inspect_prompts, args)\n",
    "    )\n",
    "\n",
    "    inspect_texts = model_utils.add_chat_template(inspect_texts, model_name)\n",
    "\n",
    "    inspect_dataloader = data_utils.create_simple_dataloader(\n",
    "        inspect_texts,\n",
    "        inspect_labels,\n",
    "        model_name,\n",
    "        device=device,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    all_batch_results = []\n",
    "\n",
    "    for batch in tqdm(inspect_dataloader):\n",
    "        input_ids, attention_mask, labels, idx_batch = batch\n",
    "\n",
    "        model_inputs = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "        }\n",
    "        batch_results = attribution.compute_attributions(\n",
    "            model,\n",
    "            tokenizer,\n",
    "            sae,\n",
    "            model_inputs,\n",
    "            labels,\n",
    "            chosen_layers,\n",
    "            submodules,\n",
    "            yes_vs_no_loss_fn,\n",
    "        )\n",
    "        batch_results = batch_results[chosen_layers[0]]\n",
    "\n",
    "        batch_results[\"encoded_acts_BLF\"] = batch_results[\"encoded_acts_BLF\"][\n",
    "            :, :, top_k_ids\n",
    "        ]\n",
    "        batch_results[\"effects_BLF\"] = batch_results[\"effects_BLF\"][:, :, top_k_ids]\n",
    "        batch_results[\"grad_x_dot_decoder_BLF\"] = batch_results[\n",
    "            \"grad_x_dot_decoder_BLF\"\n",
    "        ][:, :, top_k_ids]\n",
    "        all_batch_results.append(batch_results)\n",
    "    return all_batch_results\n",
    "\n",
    "all_attrib_batch_results = get_attrib_acts(model, tokenizer, sae, top_k_ids, batch_size, device, chosen_layers, submodules, yes_vs_no_loss_fn, downsample=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrib_html_activations = []\n",
    "\n",
    "\n",
    "# def reshape_attrib_acts(\n",
    "#     all_batch_results: dict, gradients: bool = False\n",
    "# ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "#     max_len = 0\n",
    "#     for batch_results in all_batch_results:\n",
    "#         model_inputs = batch_results[\"model_inputs\"]\n",
    "#         input_tokens_BL = model_inputs[\"input_ids\"].cpu()\n",
    "#         max_len = max(max_len, input_tokens_BL.shape[1])\n",
    "\n",
    "#     padded_tokens_list = []\n",
    "#     padded_acts_list = []\n",
    "#     labels_list = []\n",
    "\n",
    "#     print(max_len)\n",
    "\n",
    "#     for batch_results in all_batch_results:\n",
    "#         # print(batch_results.keys())\n",
    "#         # print(batch_results)\n",
    "#         model_inputs = batch_results[\"model_inputs\"]\n",
    "#         predicted_tokens = batch_results[\"predicted_tokens\"]\n",
    "#         input_tokens_BL = model_inputs[\"input_ids\"].cpu()\n",
    "#         sae_acts_BLF = batch_results[\"encoded_acts_BLF\"]\n",
    "#         effects_BLF = batch_results[\"effects_BLF\"]\n",
    "#         grad_x_dot_decoder_BLF = batch_results[\"grad_x_dot_decoder_BLF\"]\n",
    "#         labels_B = batch_results[\"labels\"]\n",
    "#         labels_list.append(labels_B)\n",
    "\n",
    "#         # print(sae_acts_BLF.shape)\n",
    "#         # print(effects_BLF.shape)\n",
    "#         # print(grad_x_dot_decoder_BLF.shape)\n",
    "#         # print(predicted_tokens)\n",
    "#         # print(input_tokens_BL)\n",
    "\n",
    "#         B, current_L, F = sae_acts_BLF.shape\n",
    "\n",
    "#         input_tokens_FBL = einops.repeat(input_tokens_BL, \"B L -> F B L\", F=F)\n",
    "#         # print(input_tokens_FBL.shape)\n",
    "\n",
    "#         if gradients:\n",
    "#             chosen_acts_BLF = grad_x_dot_decoder_BLF.clone()\n",
    "#         else:\n",
    "#             chosen_acts_BLF = sae_acts_BLF.clone()\n",
    "#         chosen_acts_FBL = einops.rearrange(chosen_acts_BLF, \"B L F -> F B L\")\n",
    "#         chosen_acts_FBL = chosen_acts_FBL.to(dtype=torch.float32)\n",
    "#         # print(chosen_acts_FBL.shape)\n",
    "\n",
    "#         pad_len = max_len - current_L\n",
    "\n",
    "#         # Pad the last dimension (L)\n",
    "#         # The padding tuple is (pad_left, pad_right) for the last dimension\n",
    "#         padded_input_tokens_FBL = torch.nn.functional.pad(\n",
    "#             input_tokens_FBL,\n",
    "#             (0, pad_len),\n",
    "#             mode=\"constant\",\n",
    "#             value=tokenizer.pad_token_id,\n",
    "#         )\n",
    "#         padded_chosen_acts_FBL = torch.nn.functional.pad(\n",
    "#             chosen_acts_FBL, (0, pad_len), mode=\"constant\", value=0\n",
    "#         )\n",
    "#         # --- Padding End ---\n",
    "\n",
    "#         padded_tokens_list.append(padded_input_tokens_FBL)\n",
    "#         padded_acts_list.append(padded_chosen_acts_FBL)\n",
    "\n",
    "#     all_tokens_FBL = torch.cat(padded_tokens_list, dim=1)\n",
    "#     all_acts_FBL = torch.cat(padded_acts_list, dim=1)\n",
    "#     labels_B = torch.cat(labels_list, dim=0)\n",
    "\n",
    "#     print(all_tokens_FBL.shape)\n",
    "#     print(all_acts_FBL.shape)\n",
    "#     print(labels_B.shape)\n",
    "\n",
    "#     return all_tokens_FBL, all_acts_FBL, labels_B\n",
    "\n",
    "\n",
    "# def analyze_acts(\n",
    "#     acts_FBL: torch.Tensor,\n",
    "#     tokens_FBL: torch.Tensor,\n",
    "#     labels_B: torch.Tensor,\n",
    "#     top_k_ids: torch.Tensor,\n",
    "#     top_k_vals: torch.Tensor,\n",
    "#     gradients: bool = False\n",
    "# ):\n",
    "#     print(acts_FBL.shape)\n",
    "#     print(tokens_FBL.shape)\n",
    "#     print(labels_B)\n",
    "\n",
    "#     pos_mask_K = labels_B == 1\n",
    "#     neg_mask_K = labels_B == 0\n",
    "\n",
    "#     print(pos_mask_K)\n",
    "#     print(neg_mask_K)\n",
    "\n",
    "#     print(acts_FBL.shape)\n",
    "\n",
    "#     pos_acts_FKL = acts_FBL[:, pos_mask_K, :]\n",
    "#     neg_acts_FKL = acts_FBL[:, neg_mask_K, :]\n",
    "\n",
    "#     if gradients:\n",
    "#         pos_acts_FKL = pos_acts_FKL[:, :, -10:]\n",
    "#         neg_acts_FKL = neg_acts_FKL[:, :, -10:]\n",
    "#         neg_acts_FKL = neg_acts_FKL * -1\n",
    "\n",
    "#     mean_pos_acts_F = pos_acts_FKL.mean(dim=(1, 2))\n",
    "#     mean_neg_acts_F = neg_acts_FKL.mean(dim=(1, 2))\n",
    "\n",
    "#     torch.set_printoptions(precision=6, sci_mode=False)\n",
    "\n",
    "#     print(mean_pos_acts_F)\n",
    "#     print(mean_neg_acts_F)\n",
    "\n",
    "#     ratios = mean_pos_acts_F / mean_neg_acts_F\n",
    "\n",
    "#     print(ratios)\n",
    "\n",
    "#     for i in range(top_k_ids.shape[0]):\n",
    "#         print()\n",
    "#         print(f\"Feature {i}, feature idx: {top_k_ids[i]}, value: {top_k_vals[i]:.5f}\")\n",
    "#         print(f\"Pos acts: {mean_pos_acts_F[i]:.5f}, Neg acts: {mean_neg_acts_F[i]:.5f}, Ratio: {ratios[i]:.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "# all_attrib_tokens_FBL, all_attrib_acts_FBL, all_attrib_labels_B = reshape_attrib_acts(\n",
    "#     all_attrib_batch_results, gradients=True\n",
    "# )\n",
    "\n",
    "# analyze_acts(\n",
    "#     all_attrib_acts_FBL,\n",
    "#     all_attrib_tokens_FBL,\n",
    "#     all_attrib_labels_B,\n",
    "#     top_k_ids,\n",
    "#     top_k_vals,\n",
    "#     gradients=True\n",
    "# )\n",
    "\n",
    "# # html_activations = create_html_activations(all_attrib_tokens_FBL, all_attrib_acts_FBL, num_display=5, k=all_attrib_acts_FBL.shape[1])\n",
    "\n",
    "# # with open(\"prompts_html_activations.pkl\", \"wb\") as f:\n",
    "# #     pickle.dump(html_activations, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... existing code ...\n",
    "\n",
    "\n",
    "def reshape_attrib_acts(\n",
    "    all_batch_results: dict, gradients: bool = False\n",
    ") -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    # ... existing code in reshape_attrib_acts ...\n",
    "    # No changes needed inside this function itself\n",
    "    max_len = 0\n",
    "    for batch_results in all_batch_results:\n",
    "        model_inputs = batch_results[\"model_inputs\"]\n",
    "        input_tokens_BL = model_inputs[\"input_ids\"].cpu()\n",
    "        max_len = max(max_len, input_tokens_BL.shape[1])\n",
    "\n",
    "    padded_tokens_list = []\n",
    "    padded_acts_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # print(max_len)\n",
    "\n",
    "    for batch_results in all_batch_results:\n",
    "        # print(batch_results.keys())\n",
    "        # print(batch_results)\n",
    "        model_inputs = batch_results[\"model_inputs\"]\n",
    "        predicted_tokens = batch_results[\"predicted_tokens\"]\n",
    "        input_tokens_BL = model_inputs[\"input_ids\"].cpu()\n",
    "        sae_acts_BLF = batch_results[\"encoded_acts_BLF\"]\n",
    "        effects_BLF = batch_results[\"effects_BLF\"]\n",
    "        grad_x_dot_decoder_BLF = batch_results[\"grad_x_dot_decoder_BLF\"]\n",
    "        labels_B = batch_results[\"labels\"]\n",
    "        labels_list.append(labels_B)\n",
    "\n",
    "        # print(sae_acts_BLF.shape)\n",
    "        # print(effects_BLF.shape)\n",
    "        # print(grad_x_dot_decoder_BLF.shape)\n",
    "        # print(predicted_tokens)\n",
    "        # print(input_tokens_BL)\n",
    "\n",
    "        B, current_L, F = sae_acts_BLF.shape\n",
    "\n",
    "        input_tokens_FBL = einops.repeat(input_tokens_BL, \"B L -> F B L\", F=F)\n",
    "        # print(input_tokens_FBL.shape)\n",
    "\n",
    "        if gradients:\n",
    "            chosen_acts_BLF = grad_x_dot_decoder_BLF.clone()\n",
    "        else:\n",
    "            chosen_acts_BLF = sae_acts_BLF.clone()\n",
    "        chosen_acts_FBL = einops.rearrange(chosen_acts_BLF, \"B L F -> F B L\")\n",
    "        chosen_acts_FBL = chosen_acts_FBL.to(dtype=torch.float32)\n",
    "        # print(chosen_acts_FBL.shape)\n",
    "\n",
    "        pad_len = max_len - current_L\n",
    "\n",
    "        # Pad the last dimension (L)\n",
    "        # The padding tuple is (pad_left, pad_right) for the last dimension\n",
    "        padded_input_tokens_FBL = torch.nn.functional.pad(\n",
    "            input_tokens_FBL,\n",
    "            (0, pad_len),\n",
    "            mode=\"constant\",\n",
    "            value=tokenizer.pad_token_id,\n",
    "        )\n",
    "        padded_chosen_acts_FBL = torch.nn.functional.pad(\n",
    "            chosen_acts_FBL, (0, pad_len), mode=\"constant\", value=0\n",
    "        )\n",
    "        # --- Padding End ---\n",
    "\n",
    "        padded_tokens_list.append(padded_input_tokens_FBL)\n",
    "        padded_acts_list.append(padded_chosen_acts_FBL)\n",
    "\n",
    "    all_tokens_FBL = torch.cat(padded_tokens_list, dim=1)\n",
    "    all_acts_FBL = torch.cat(padded_acts_list, dim=1)\n",
    "    labels_B = torch.cat(labels_list, dim=0)\n",
    "\n",
    "    # print(all_tokens_FBL.shape)\n",
    "    # print(all_acts_FBL.shape)\n",
    "    # print(labels_B.shape)\n",
    "\n",
    "    return all_tokens_FBL, all_acts_FBL, labels_B\n",
    "\n",
    "\n",
    "def analyze_acts(\n",
    "    acts_FBL: torch.Tensor,\n",
    "    acts_grad_FBL: torch.Tensor,  # Added gradient activations\n",
    "    tokens_FBL: torch.Tensor,\n",
    "    labels_B: torch.Tensor,\n",
    "    top_k_ids: torch.Tensor,\n",
    "    top_k_vals: torch.Tensor,\n",
    "    output_filename: str,\n",
    "):\n",
    "    print(f\"Acts shape: {acts_FBL.shape}\")\n",
    "    print(f\"Grad Acts shape: {acts_grad_FBL.shape}\")\n",
    "    print(f\"Tokens shape: {tokens_FBL.shape}\")\n",
    "    print(f\"Labels: {labels_B}\")\n",
    "\n",
    "    pos_mask_K = labels_B == 1\n",
    "    neg_mask_K = labels_B == 0\n",
    "\n",
    "    # print(f\"Pos mask: {pos_mask_K}\")\n",
    "    # print(f\"Neg mask: {neg_mask_K}\")\n",
    "\n",
    "    # --- Regular Activations ---\n",
    "    pos_acts_FKL = acts_FBL[:, pos_mask_K, :]\n",
    "    neg_acts_FKL = acts_FBL[:, neg_mask_K, :]\n",
    "    mean_pos_acts_F = pos_acts_FKL.mean(dim=(1, 2))\n",
    "    mean_neg_acts_F = neg_acts_FKL.mean(dim=(1, 2))\n",
    "    ratios = mean_pos_acts_F / mean_neg_acts_F\n",
    "    ratios = torch.nan_to_num(ratios, nan=0.0)  # Handle potential division by zero\n",
    "\n",
    "    # --- Gradient Activations ---\n",
    "    pos_acts_grad_FKL = acts_grad_FBL[:, pos_mask_K, :]\n",
    "    neg_acts_grad_FKL = acts_grad_FBL[:, neg_mask_K, :]\n",
    "    # Take last 10 tokens for gradients and invert negative examples as before\n",
    "    # pos_acts_grad_FKL = pos_acts_grad_FKL[:, :, -40:]\n",
    "    # neg_acts_grad_FKL = neg_acts_grad_FKL[:, :, -40:]\n",
    "\n",
    "    pos_acts_grad_FKL = pos_acts_grad_FKL[:, :, -10:]\n",
    "    neg_acts_grad_FKL = neg_acts_grad_FKL[:, :, -10:]\n",
    "    neg_acts_grad_FKL = neg_acts_grad_FKL * -1\n",
    "    mean_pos_acts_grad_F = pos_acts_grad_FKL.mean(dim=(1, 2))\n",
    "    mean_neg_acts_grad_F = neg_acts_grad_FKL.mean(dim=(1, 2))\n",
    "    ratios_grad = mean_pos_acts_grad_F / mean_neg_acts_grad_F\n",
    "    ratios_grad = torch.nan_to_num(\n",
    "        ratios_grad, nan=0.0\n",
    "    )  # Handle potential division by zero\n",
    "\n",
    "    torch.set_printoptions(precision=5, sci_mode=False)\n",
    "\n",
    "    print(\"\\n--- Analysis per Feature ---\")\n",
    "    header = f\"{'Feature':<7} {'Idx':<5} {'Value':<10} | {'Acts Pos':<10} {'Acts Neg':<10} {'Acts Ratio':<10} | {'Grad Pos':<10} {'Grad Neg':<10} {'Grad Ratio':<10}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "\n",
    "    for i in range(top_k_ids.shape[0]):\n",
    "        print(\n",
    "            f\"Feature {i:<2}, \"\n",
    "            f\"idx: {top_k_ids[i]:<5}, \"\n",
    "            f\"value: {top_k_vals[i]:<10.5f} | \"\n",
    "            f\"acts pos: {mean_pos_acts_F[i]:<10.5f}, \"\n",
    "            f\"acts neg: {mean_neg_acts_F[i]:<10.5f}, \"\n",
    "            f\"acts ratio: {ratios[i]:<10.5f} | \"\n",
    "            # f\"grad pos: {mean_pos_acts_grad_F[i]:<10.5f}, \"\n",
    "            # f\"grad neg: {mean_neg_acts_grad_F[i]:<10.5f}, \"\n",
    "            # f\"grad ratio: {ratios_grad[i]:<10.5f}\"\n",
    "        )\n",
    "\n",
    "    data = {\n",
    "        \"top_k_ids\": top_k_ids,\n",
    "        \"top_k_vals\": top_k_vals,\n",
    "        \"mean_pos_acts_F\": mean_pos_acts_F,\n",
    "        \"mean_neg_acts_F\": mean_neg_acts_F,\n",
    "        \"ratios\": ratios,\n",
    "        \"mean_pos_acts_grad_F\": mean_pos_acts_grad_F,\n",
    "        \"mean_neg_acts_grad_F\": mean_neg_acts_grad_F,\n",
    "        \"ratios_grad\": ratios_grad,\n",
    "    }\n",
    "\n",
    "    with open(output_filename, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "output_dir = \"bias_data_notebook\"\n",
    "output_filename = f\"{bias_type}_{model_name}_layer_{chosen_layers[0]}_downsample_{downsample}_trainer_id_{trainer_id}.pkl\".replace(\"/\", \"_\")\n",
    "output_filename = os.path.join(output_dir, output_filename)\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- Call reshape_attrib_acts twice ---\n",
    "print(\"Reshaping standard activations...\")\n",
    "all_attrib_tokens_FBL, all_attrib_acts_FBL, all_attrib_labels_B = reshape_attrib_acts(\n",
    "    all_attrib_batch_results, gradients=False\n",
    ")\n",
    "print(\"\\nReshaping gradient activations...\")\n",
    "_, all_attrib_acts_grad_FBL, _ = reshape_attrib_acts(  # Tokens and labels are the same\n",
    "    all_attrib_batch_results, gradients=True\n",
    ")\n",
    "print(\"\\nRunning analysis...\")\n",
    "analyze_acts(\n",
    "    all_attrib_acts_FBL,\n",
    "    all_attrib_acts_grad_FBL,  # Pass gradient acts\n",
    "    all_attrib_tokens_FBL,\n",
    "    all_attrib_labels_B,\n",
    "    top_k_ids,\n",
    "    top_k_vals,\n",
    "    output_filename,\n",
    ")\n",
    "\n",
    "html_activations = create_html_activations(\n",
    "    all_attrib_tokens_FBL,\n",
    "    all_attrib_acts_grad_FBL,\n",
    "    num_display=12,\n",
    "    k=all_attrib_acts_FBL.shape[1],\n",
    ")\n",
    "\n",
    "with open(\"prompts_html_activations.pkl\", \"wb\") as f:\n",
    "    pickle.dump(html_activations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrib_html_activations = []\n",
    "\n",
    "\n",
    "# def reshape_attrib_acts(\n",
    "#     all_batch_results: dict, gradients: bool = False\n",
    "# ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "#     max_len = 0\n",
    "#     for batch_results in all_batch_results:\n",
    "#         model_inputs = batch_results[\"model_inputs\"]\n",
    "#         input_tokens_BL = model_inputs[\"input_ids\"].cpu()\n",
    "#         max_len = max(max_len, input_tokens_BL.shape[1])\n",
    "\n",
    "#     padded_tokens_list = []\n",
    "#     padded_acts_list = []\n",
    "#     labels_list = []\n",
    "\n",
    "#     print(max_len)\n",
    "\n",
    "#     for batch_results in all_batch_results:\n",
    "#         # print(batch_results.keys())\n",
    "#         # print(batch_results)\n",
    "#         model_inputs = batch_results[\"model_inputs\"]\n",
    "#         predicted_tokens = batch_results[\"predicted_tokens\"]\n",
    "#         input_tokens_BL = model_inputs[\"input_ids\"].cpu()\n",
    "#         sae_acts_BLF = batch_results[\"encoded_acts_BLF\"]\n",
    "#         effects_BLF = batch_results[\"effects_BLF\"]\n",
    "#         grad_x_dot_decoder_BLF = batch_results[\"grad_x_dot_decoder_BLF\"]\n",
    "#         labels_B = batch_results[\"labels\"]\n",
    "#         labels_list.append(labels_B)\n",
    "\n",
    "#         # print(sae_acts_BLF.shape)\n",
    "#         # print(effects_BLF.shape)\n",
    "#         # print(grad_x_dot_decoder_BLF.shape)\n",
    "#         # print(predicted_tokens)\n",
    "#         # print(input_tokens_BL)\n",
    "\n",
    "#         B, current_L, F = sae_acts_BLF.shape\n",
    "\n",
    "#         input_tokens_FBL = einops.repeat(input_tokens_BL, \"B L -> F B L\", F=F)\n",
    "#         # print(input_tokens_FBL.shape)\n",
    "\n",
    "#         if gradients:\n",
    "#             chosen_acts_BLF = grad_x_dot_decoder_BLF.clone()\n",
    "#         else:\n",
    "#             chosen_acts_BLF = sae_acts_BLF.clone()\n",
    "#         chosen_acts_FBL = einops.rearrange(chosen_acts_BLF, \"B L F -> F B L\")\n",
    "#         chosen_acts_FBL = chosen_acts_FBL.to(dtype=torch.float32)\n",
    "#         # print(chosen_acts_FBL.shape)\n",
    "\n",
    "#         pad_len = max_len - current_L\n",
    "\n",
    "#         # Pad the last dimension (L)\n",
    "#         # The padding tuple is (pad_left, pad_right) for the last dimension\n",
    "#         padded_input_tokens_FBL = torch.nn.functional.pad(\n",
    "#             input_tokens_FBL,\n",
    "#             (0, pad_len),\n",
    "#             mode=\"constant\",\n",
    "#             value=tokenizer.pad_token_id,\n",
    "#         )\n",
    "#         padded_chosen_acts_FBL = torch.nn.functional.pad(\n",
    "#             chosen_acts_FBL, (0, pad_len), mode=\"constant\", value=0\n",
    "#         )\n",
    "#         # --- Padding End ---\n",
    "\n",
    "#         padded_tokens_list.append(padded_input_tokens_FBL)\n",
    "#         padded_acts_list.append(padded_chosen_acts_FBL)\n",
    "\n",
    "#     all_tokens_FBL = torch.cat(padded_tokens_list, dim=1)\n",
    "#     all_acts_FBL = torch.cat(padded_acts_list, dim=1)\n",
    "#     labels_B = torch.cat(labels_list, dim=0)\n",
    "\n",
    "#     print(all_tokens_FBL.shape)\n",
    "#     print(all_acts_FBL.shape)\n",
    "#     print(labels_B.shape)\n",
    "\n",
    "#     return all_tokens_FBL, all_acts_FBL, labels_B\n",
    "\n",
    "\n",
    "# def analyze_acts(\n",
    "#     acts_FBL: torch.Tensor,\n",
    "#     tokens_FBL: torch.Tensor,\n",
    "#     labels_B: torch.Tensor,\n",
    "#     top_k_ids: torch.Tensor,\n",
    "#     top_k_vals: torch.Tensor,\n",
    "#     gradients: bool = False\n",
    "# ):\n",
    "#     print(acts_FBL.shape)\n",
    "#     print(tokens_FBL.shape)\n",
    "#     print(labels_B)\n",
    "\n",
    "#     pos_mask_K = labels_B == 1\n",
    "#     neg_mask_K = labels_B == 0\n",
    "\n",
    "#     print(pos_mask_K)\n",
    "#     print(neg_mask_K)\n",
    "\n",
    "#     print(acts_FBL.shape)\n",
    "\n",
    "#     pos_acts_FKL = acts_FBL[:, pos_mask_K, :]\n",
    "#     neg_acts_FKL = acts_FBL[:, neg_mask_K, :]\n",
    "\n",
    "#     if gradients:\n",
    "#         pos_acts_FKL = pos_acts_FKL[:, :, -50:]\n",
    "#         neg_acts_FKL = neg_acts_FKL[:, :, -50:]\n",
    "#         neg_acts_FKL = neg_acts_FKL * -1\n",
    "\n",
    "#     mean_pos_acts_F = pos_acts_FKL.mean(dim=(1, 2))\n",
    "#     mean_neg_acts_F = neg_acts_FKL.mean(dim=(1, 2))\n",
    "\n",
    "#     torch.set_printoptions(precision=6, sci_mode=False)\n",
    "\n",
    "#     print(mean_pos_acts_F)\n",
    "#     print(mean_neg_acts_F)\n",
    "\n",
    "#     ratios = mean_pos_acts_F / mean_neg_acts_F\n",
    "\n",
    "#     print(ratios)\n",
    "\n",
    "#     for i in range(top_k_ids.shape[0]):\n",
    "#         print()\n",
    "#         print(f\"Feature {i}, feature idx: {top_k_ids[i]}, value: {top_k_vals[i]:.5f}\")\n",
    "#         print(f\"Pos acts: {mean_pos_acts_F[i]:.5f}, Neg acts: {mean_neg_acts_F[i]:.5f}, Ratio: {ratios[i]:.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "# all_attrib_tokens_FBL, all_attrib_acts_FBL, all_attrib_labels_B = reshape_attrib_acts(\n",
    "#     all_attrib_batch_results, gradients=True\n",
    "# )\n",
    "\n",
    "# analyze_acts(\n",
    "#     all_attrib_acts_FBL,\n",
    "#     all_attrib_tokens_FBL,\n",
    "#     all_attrib_labels_B,\n",
    "#     top_k_ids,\n",
    "#     top_k_vals,\n",
    "#     gradients=True\n",
    "# )\n",
    "\n",
    "# html_activations = create_html_activations(all_attrib_tokens_FBL, all_attrib_acts_FBL, num_display=5, k=all_attrib_acts_FBL.shape[1])\n",
    "\n",
    "# with open(\"prompts_html_activations.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(html_activations, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear_output(wait=True)\n",
    "# gc.collect()\n",
    "# html_activations = create_html_activations(all_attrib_tokens_FBL, all_attrib_acts_FBL, num_display=2, k=all_attrib_acts_FBL.shape[1])\n",
    "# for i, html_activation in enumerate(html_activations):\n",
    "#     feature_idx = top_k_ids[i]\n",
    "#     feature_val = top_k_vals[i]\n",
    "#     print(f\"Feature {i}, feature idx: {feature_idx}, value: {feature_val}\")\n",
    "#     display(html_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from copy import deepcopy\n",
    "\n",
    "# inspection_eval_config = deepcopy(eval_config)\n",
    "# inspection_eval_config.downsample = 3\n",
    "\n",
    "# inspect_df = dataset_setup.balanced_downsample(df, inspection_eval_config.downsample, random_seed)\n",
    "\n",
    "# inspect_prompts = hiring_bias_prompts.create_all_prompts_hiring_bias(inspect_df, args, inspection_eval_config)\n",
    "\n",
    "# inspect_texts, inspect_labels = hiring_bias_prompts.process_hiring_bias_resumes_prompts(inspect_prompts, args)\n",
    "\n",
    "# inspect_texts = model_utils.add_chat_template(inspect_texts, model_name)\n",
    "\n",
    "# inspect_tokens_FBL, inspect_activations_FBL = interp_utils.get_interp_prompts_user_inputs(\n",
    "#     model,\n",
    "#     submodules[0],\n",
    "#     sae,\n",
    "#     top_k_ids,\n",
    "#     inspect_texts,\n",
    "#     tokenizer=tokenizer,\n",
    "#     batch_size=batch_size * 6,\n",
    "#     k=len(inspect_texts),\n",
    "# )\n",
    "\n",
    "# num_display = 2\n",
    "\n",
    "# html_activations = display_html_activations(inspect_tokens_FBL, inspect_activations_FBL, num_display=num_display, k=len(inspect_texts))\n",
    "\n",
    "# for i, html_activation in enumerate(html_activations):\n",
    "#     feature_idx = top_k_ids[i]\n",
    "#     feature_val = top_k_vals[i]\n",
    "#     print(f\"Feature {i}, feature idx: {feature_idx}, value: {feature_val}\")\n",
    "#     display(html_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
